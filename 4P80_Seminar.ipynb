{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4P80_Seminar",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q7bjLTa2ksR"
      },
      "source": [
        "Joel Gritter & Kindeep Singh Kargil\n",
        "\n",
        "COSC 4P80 - Seminar Demo\n",
        "\n",
        "March 29, 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z51tQN3V-5ZQ"
      },
      "source": [
        "# imports for data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# imports for machine learning\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR_1giDiDHN4"
      },
      "source": [
        "# read in the notes, make an array with 0's, except for the current note\n",
        "def read_and_format(input_filepath):\n",
        "  input_data = []\n",
        "  with open(input_filepath) as input_file:\n",
        "    for line in input_file:\n",
        "      values = line.split(\",\")\n",
        "      for value in values:\n",
        "        tmp = [0.0] * 88\n",
        "        v = int(value)\n",
        "        tmp[v-1] = 1.0\n",
        "        input_data.append(tmp)\n",
        "  \n",
        "  return input_data\n",
        "  \n",
        "\n",
        "input_data = read_and_format(\"k330-allegro-moderato.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZmz0vCDrdfe",
        "outputId": "aacfeb95-6583-4bfc-af74-25c23e60dacc"
      },
      "source": [
        "# get the previous 20 notes, predict the next note\n",
        "def generate_datasets(input_array, n_prev = 20):\n",
        "  temp_x = [input_array[i:i+n_prev] for i in range(len(input_array) - n_prev)]\n",
        "  temp_y = [input_array[i+n_prev] for i in range(len(input_array) - n_prev)]\n",
        "\n",
        "  return np.array(temp_x), np.array(temp_y)\n",
        "\n",
        "x, y = generate_datasets(input_data)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, shuffle=True)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "print(y_train[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2008, 20, 88) (2008, 88)\n",
            "(502, 20, 88) (502, 88)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be0VQFAlqlPA"
      },
      "source": [
        "# build the model itself\n",
        "model = Sequential()\n",
        "model.add(LSTM(30))\n",
        "model.add(Dense(88, activation=\"softmax\"))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odZ6VCKIsLJ8",
        "outputId": "ac8a8f08-37ab-4bf7-c2fa-0ce553e3e625"
      },
      "source": [
        "# train the model\n",
        "model.fit(x_train, y_train, batch_size=10, epochs=100, validation_split=0.05)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "191/191 [==============================] - 4s 11ms/step - loss: 3.7037 - accuracy: 0.1409 - val_loss: 2.8201 - val_accuracy: 0.1485\n",
            "Epoch 2/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 2.6582 - accuracy: 0.1591 - val_loss: 2.8059 - val_accuracy: 0.1485\n",
            "Epoch 3/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 2.6458 - accuracy: 0.1698 - val_loss: 2.7629 - val_accuracy: 0.1485\n",
            "Epoch 4/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 2.6282 - accuracy: 0.1714 - val_loss: 2.7299 - val_accuracy: 0.1485\n",
            "Epoch 5/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 2.5811 - accuracy: 0.1817 - val_loss: 2.6803 - val_accuracy: 0.1881\n",
            "Epoch 6/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 2.5178 - accuracy: 0.2112 - val_loss: 2.5997 - val_accuracy: 0.2079\n",
            "Epoch 7/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 2.4505 - accuracy: 0.2361 - val_loss: 2.5154 - val_accuracy: 0.2574\n",
            "Epoch 8/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 2.3360 - accuracy: 0.2798 - val_loss: 2.4402 - val_accuracy: 0.3267\n",
            "Epoch 9/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 2.2944 - accuracy: 0.3003 - val_loss: 2.3884 - val_accuracy: 0.3366\n",
            "Epoch 10/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 2.2360 - accuracy: 0.3025 - val_loss: 2.3346 - val_accuracy: 0.3465\n",
            "Epoch 11/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 2.1712 - accuracy: 0.3207 - val_loss: 2.2937 - val_accuracy: 0.3366\n",
            "Epoch 12/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 2.0933 - accuracy: 0.3348 - val_loss: 2.2447 - val_accuracy: 0.3069\n",
            "Epoch 13/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 2.0795 - accuracy: 0.3411 - val_loss: 2.2199 - val_accuracy: 0.3267\n",
            "Epoch 14/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 2.0409 - accuracy: 0.3376 - val_loss: 2.1993 - val_accuracy: 0.3069\n",
            "Epoch 15/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 1.9903 - accuracy: 0.3386 - val_loss: 2.1736 - val_accuracy: 0.2871\n",
            "Epoch 16/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.9809 - accuracy: 0.3633 - val_loss: 2.1441 - val_accuracy: 0.3069\n",
            "Epoch 17/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.9330 - accuracy: 0.3641 - val_loss: 2.1377 - val_accuracy: 0.2970\n",
            "Epoch 18/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.9030 - accuracy: 0.3665 - val_loss: 2.1287 - val_accuracy: 0.3366\n",
            "Epoch 19/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.8603 - accuracy: 0.3962 - val_loss: 2.1426 - val_accuracy: 0.3366\n",
            "Epoch 20/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.8339 - accuracy: 0.3950 - val_loss: 2.0968 - val_accuracy: 0.3564\n",
            "Epoch 21/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.7629 - accuracy: 0.4384 - val_loss: 2.0954 - val_accuracy: 0.3762\n",
            "Epoch 22/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 1.7491 - accuracy: 0.4556 - val_loss: 2.0778 - val_accuracy: 0.3663\n",
            "Epoch 23/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.7118 - accuracy: 0.4615 - val_loss: 2.0799 - val_accuracy: 0.3564\n",
            "Epoch 24/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 1.7364 - accuracy: 0.4456 - val_loss: 2.0482 - val_accuracy: 0.4257\n",
            "Epoch 25/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.6796 - accuracy: 0.4468 - val_loss: 2.0018 - val_accuracy: 0.4356\n",
            "Epoch 26/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.6676 - accuracy: 0.4585 - val_loss: 2.0321 - val_accuracy: 0.3762\n",
            "Epoch 27/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.6186 - accuracy: 0.4785 - val_loss: 2.0046 - val_accuracy: 0.4257\n",
            "Epoch 28/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.6150 - accuracy: 0.5000 - val_loss: 2.0659 - val_accuracy: 0.3861\n",
            "Epoch 29/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 1.6445 - accuracy: 0.4861 - val_loss: 1.9529 - val_accuracy: 0.4356\n",
            "Epoch 30/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.5715 - accuracy: 0.4993 - val_loss: 1.9787 - val_accuracy: 0.4356\n",
            "Epoch 31/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.5569 - accuracy: 0.5139 - val_loss: 1.9590 - val_accuracy: 0.4356\n",
            "Epoch 32/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.5410 - accuracy: 0.5146 - val_loss: 1.9588 - val_accuracy: 0.3861\n",
            "Epoch 33/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 1.4647 - accuracy: 0.5429 - val_loss: 2.0335 - val_accuracy: 0.3960\n",
            "Epoch 34/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.4634 - accuracy: 0.5509 - val_loss: 1.9467 - val_accuracy: 0.4455\n",
            "Epoch 35/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.4449 - accuracy: 0.5488 - val_loss: 1.9128 - val_accuracy: 0.4455\n",
            "Epoch 36/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.3774 - accuracy: 0.5826 - val_loss: 1.8704 - val_accuracy: 0.4059\n",
            "Epoch 37/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.3832 - accuracy: 0.5667 - val_loss: 1.9035 - val_accuracy: 0.4356\n",
            "Epoch 38/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 1.3498 - accuracy: 0.5841 - val_loss: 1.8579 - val_accuracy: 0.4455\n",
            "Epoch 39/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.3301 - accuracy: 0.5897 - val_loss: 1.8366 - val_accuracy: 0.4752\n",
            "Epoch 40/100\n",
            "191/191 [==============================] - 2s 9ms/step - loss: 1.3041 - accuracy: 0.6074 - val_loss: 1.8852 - val_accuracy: 0.4752\n",
            "Epoch 41/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.2719 - accuracy: 0.6060 - val_loss: 1.8263 - val_accuracy: 0.4455\n",
            "Epoch 42/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.2516 - accuracy: 0.6033 - val_loss: 1.8717 - val_accuracy: 0.4554\n",
            "Epoch 43/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.2675 - accuracy: 0.5954 - val_loss: 1.8127 - val_accuracy: 0.5050\n",
            "Epoch 44/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.1652 - accuracy: 0.6409 - val_loss: 1.8365 - val_accuracy: 0.5050\n",
            "Epoch 45/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.1654 - accuracy: 0.6389 - val_loss: 1.7970 - val_accuracy: 0.4752\n",
            "Epoch 46/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.1542 - accuracy: 0.6524 - val_loss: 1.8216 - val_accuracy: 0.4851\n",
            "Epoch 47/100\n",
            "191/191 [==============================] - 2s 9ms/step - loss: 1.1909 - accuracy: 0.6237 - val_loss: 1.7530 - val_accuracy: 0.4950\n",
            "Epoch 48/100\n",
            "191/191 [==============================] - 2s 9ms/step - loss: 1.0707 - accuracy: 0.6763 - val_loss: 1.7474 - val_accuracy: 0.4851\n",
            "Epoch 49/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.0886 - accuracy: 0.6567 - val_loss: 1.7822 - val_accuracy: 0.5149\n",
            "Epoch 50/100\n",
            "191/191 [==============================] - 2s 9ms/step - loss: 1.0773 - accuracy: 0.6689 - val_loss: 1.7392 - val_accuracy: 0.5050\n",
            "Epoch 51/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 1.0305 - accuracy: 0.6959 - val_loss: 1.6797 - val_accuracy: 0.5644\n",
            "Epoch 52/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 1.0098 - accuracy: 0.6880 - val_loss: 1.7743 - val_accuracy: 0.5050\n",
            "Epoch 53/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 1.0558 - accuracy: 0.6770 - val_loss: 1.7008 - val_accuracy: 0.5248\n",
            "Epoch 54/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 1.0045 - accuracy: 0.7008 - val_loss: 1.7315 - val_accuracy: 0.5050\n",
            "Epoch 55/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.9913 - accuracy: 0.7100 - val_loss: 1.6567 - val_accuracy: 0.5446\n",
            "Epoch 56/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.9638 - accuracy: 0.7172 - val_loss: 1.7464 - val_accuracy: 0.5545\n",
            "Epoch 57/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.9172 - accuracy: 0.7281 - val_loss: 1.7604 - val_accuracy: 0.5050\n",
            "Epoch 58/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.9074 - accuracy: 0.7335 - val_loss: 1.6396 - val_accuracy: 0.5743\n",
            "Epoch 59/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.9027 - accuracy: 0.7389 - val_loss: 1.6013 - val_accuracy: 0.5545\n",
            "Epoch 60/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.9039 - accuracy: 0.7420 - val_loss: 1.6823 - val_accuracy: 0.5248\n",
            "Epoch 61/100\n",
            "191/191 [==============================] - 2s 9ms/step - loss: 0.8057 - accuracy: 0.7729 - val_loss: 1.5726 - val_accuracy: 0.5446\n",
            "Epoch 62/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.8367 - accuracy: 0.7799 - val_loss: 1.6561 - val_accuracy: 0.5545\n",
            "Epoch 63/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.8253 - accuracy: 0.7659 - val_loss: 1.5833 - val_accuracy: 0.5545\n",
            "Epoch 64/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.8171 - accuracy: 0.7669 - val_loss: 1.6167 - val_accuracy: 0.5842\n",
            "Epoch 65/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 0.8370 - accuracy: 0.7667 - val_loss: 1.5377 - val_accuracy: 0.5446\n",
            "Epoch 66/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.8251 - accuracy: 0.7693 - val_loss: 1.5546 - val_accuracy: 0.5644\n",
            "Epoch 67/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.7641 - accuracy: 0.7856 - val_loss: 1.5653 - val_accuracy: 0.5941\n",
            "Epoch 68/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.8017 - accuracy: 0.7715 - val_loss: 1.5716 - val_accuracy: 0.5941\n",
            "Epoch 69/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 0.7790 - accuracy: 0.7901 - val_loss: 1.5235 - val_accuracy: 0.5941\n",
            "Epoch 70/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.7128 - accuracy: 0.8148 - val_loss: 1.5321 - val_accuracy: 0.5842\n",
            "Epoch 71/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 0.7004 - accuracy: 0.8113 - val_loss: 1.5232 - val_accuracy: 0.6337\n",
            "Epoch 72/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 0.6453 - accuracy: 0.8359 - val_loss: 1.5558 - val_accuracy: 0.5644\n",
            "Epoch 73/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.6698 - accuracy: 0.8219 - val_loss: 1.4801 - val_accuracy: 0.6337\n",
            "Epoch 74/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.6379 - accuracy: 0.8346 - val_loss: 1.4892 - val_accuracy: 0.6436\n",
            "Epoch 75/100\n",
            "191/191 [==============================] - 2s 9ms/step - loss: 0.6347 - accuracy: 0.8344 - val_loss: 1.4734 - val_accuracy: 0.6238\n",
            "Epoch 76/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.6627 - accuracy: 0.8164 - val_loss: 1.4596 - val_accuracy: 0.6337\n",
            "Epoch 77/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.6354 - accuracy: 0.8236 - val_loss: 1.4952 - val_accuracy: 0.6337\n",
            "Epoch 78/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.6039 - accuracy: 0.8465 - val_loss: 1.3825 - val_accuracy: 0.6733\n",
            "Epoch 79/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 0.6111 - accuracy: 0.8415 - val_loss: 1.4855 - val_accuracy: 0.6238\n",
            "Epoch 80/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 0.5424 - accuracy: 0.8660 - val_loss: 1.3896 - val_accuracy: 0.6436\n",
            "Epoch 81/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.5572 - accuracy: 0.8594 - val_loss: 1.4561 - val_accuracy: 0.6238\n",
            "Epoch 82/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.5489 - accuracy: 0.8536 - val_loss: 1.4081 - val_accuracy: 0.6535\n",
            "Epoch 83/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.5070 - accuracy: 0.8746 - val_loss: 1.4229 - val_accuracy: 0.5941\n",
            "Epoch 84/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.5408 - accuracy: 0.8660 - val_loss: 1.3634 - val_accuracy: 0.6535\n",
            "Epoch 85/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.5329 - accuracy: 0.8632 - val_loss: 1.3635 - val_accuracy: 0.6535\n",
            "Epoch 86/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.5105 - accuracy: 0.8728 - val_loss: 1.4154 - val_accuracy: 0.6040\n",
            "Epoch 87/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.5333 - accuracy: 0.8509 - val_loss: 1.3735 - val_accuracy: 0.6634\n",
            "Epoch 88/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.5178 - accuracy: 0.8518 - val_loss: 1.3349 - val_accuracy: 0.6634\n",
            "Epoch 89/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 0.5154 - accuracy: 0.8689 - val_loss: 1.3555 - val_accuracy: 0.6535\n",
            "Epoch 90/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.4538 - accuracy: 0.8773 - val_loss: 1.3078 - val_accuracy: 0.6832\n",
            "Epoch 91/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 0.4663 - accuracy: 0.8695 - val_loss: 1.4226 - val_accuracy: 0.6634\n",
            "Epoch 92/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.4673 - accuracy: 0.8910 - val_loss: 1.3531 - val_accuracy: 0.6634\n",
            "Epoch 93/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.4716 - accuracy: 0.8848 - val_loss: 1.3692 - val_accuracy: 0.5941\n",
            "Epoch 94/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.4760 - accuracy: 0.8716 - val_loss: 1.2974 - val_accuracy: 0.7030\n",
            "Epoch 95/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 0.4845 - accuracy: 0.8844 - val_loss: 1.2741 - val_accuracy: 0.6931\n",
            "Epoch 96/100\n",
            "191/191 [==============================] - 2s 8ms/step - loss: 0.4199 - accuracy: 0.9050 - val_loss: 1.2926 - val_accuracy: 0.6535\n",
            "Epoch 97/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.3980 - accuracy: 0.8938 - val_loss: 1.2892 - val_accuracy: 0.6733\n",
            "Epoch 98/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.4050 - accuracy: 0.8984 - val_loss: 1.2891 - val_accuracy: 0.7129\n",
            "Epoch 99/100\n",
            "191/191 [==============================] - 1s 7ms/step - loss: 0.4109 - accuracy: 0.9025 - val_loss: 1.2921 - val_accuracy: 0.6832\n",
            "Epoch 100/100\n",
            "191/191 [==============================] - 1s 8ms/step - loss: 0.4335 - accuracy: 0.8769 - val_loss: 1.3337 - val_accuracy: 0.6535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efd073f4690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucPR1Hp5vIUT",
        "outputId": "b7ace843-d9e3-4dbd-ab9a-5e8d62989583"
      },
      "source": [
        "# test the model\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 3ms/step - loss: 1.3169 - accuracy: 0.6614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3169466257095337, 0.6613546013832092]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPvGpGVwNIoD",
        "outputId": "b91d8b14-ffb7-4c2e-e4d6-6e019a7973d5"
      },
      "source": [
        "# See incorrectly predicted \n",
        "predictions = model.predict(x_test)\n",
        "incorrect_indices = []\n",
        "for (index, (prediction, target)) in enumerate(zip(predictions, y_test)):\n",
        "  pred = np.argmax(prediction)\n",
        "  tar = np.argmax(target)\n",
        "  if pred != tar:\n",
        "    incorrect_indices.append(index)\n",
        "\n",
        "print(\", \".join(map(str, incorrect_indices)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7, 8, 10, 11, 12, 16, 19, 22, 23, 25, 26, 27, 30, 31, 32, 34, 37, 44, 45, 46, 50, 53, 54, 56, 62, 66, 72, 73, 74, 79, 84, 91, 95, 97, 98, 99, 111, 115, 116, 119, 121, 122, 126, 129, 130, 131, 134, 136, 140, 141, 146, 148, 149, 156, 167, 170, 172, 174, 177, 187, 191, 196, 198, 203, 206, 210, 215, 217, 220, 221, 222, 227, 228, 233, 234, 239, 248, 251, 252, 256, 257, 258, 259, 262, 265, 268, 269, 272, 273, 276, 279, 281, 282, 287, 289, 292, 296, 298, 305, 308, 309, 311, 313, 317, 322, 325, 327, 330, 337, 338, 341, 342, 346, 349, 350, 356, 358, 359, 360, 362, 366, 367, 370, 372, 373, 375, 376, 377, 380, 381, 383, 386, 390, 393, 394, 395, 396, 398, 400, 402, 408, 409, 417, 419, 420, 425, 428, 429, 430, 435, 436, 442, 445, 447, 451, 453, 455, 459, 463, 466, 470, 472, 483, 488, 490, 493, 496, 498, 499, 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2WwsRUFm5u0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81108fa8-d022-4633-97ae-19d6477c7ae6"
      },
      "source": [
        "# Predict song\n",
        "test_in = x_test[0]\n",
        "\n",
        "# initial - provide inital 20 notes\n",
        "# n - how many predicted notes to add (i.e. expand by this number)\n",
        "def make_big_song(initial, n):\n",
        "  res =[ x for x in initial]\n",
        "  for _ in range(n):\n",
        "    next = model.predict(np.array([res[-20:],]))[0]\n",
        "    res.append(next)\n",
        "\n",
        "  return np.array(res)\n",
        "\n",
        "test = make_big_song(test_in, 20)\n",
        "print(test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40, 88)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}